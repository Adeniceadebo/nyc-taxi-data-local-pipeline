# ğŸš– NYC Taxi Data Ingestion with Apache Airflow

This project automates the **download and ingestion** of NYC Yellow Taxi data into a **PostgreSQL** database using **Apache Airflow**.  
---

## ğŸ§  Project Overview
The pipeline performs the following steps:

Download Dataset: Fetch monthly NYC Yellow Taxi trip data from the DataTalksClub GitHub releases.
Load to Postgres: Use Pandas and SQLAlchemy to load the dataset into a PostgreSQL table (yellow_taxi_data).
Orchestrate with Airflow: Manage task dependencies and scheduling with Airflow DAGs.

### ğŸ”¹ Tools Used
- **Apache Airflow** â€” workflow orchestration  
- **PostgreSQL** â€” data warehouse  
- **Docker & Docker Compose** â€” containerized setup  
- **Python, Pandas, SQLAlchemy** â€” data processing  
- **Redis + Celery** â€” distributed task queue for Airflow  

### ğŸ”¹ Workflow
The Airflow DAG (`data_ingestion_local`) performs:
1. **Download** â€” retrieves monthly NYC Yellow Taxi data (CSV.gz) from GitHub  
2. **Ingestion** â€” loads data into a PostgreSQL table (`yellow_taxi_data`)  

---

## âš™ï¸ Project Structure
â”œâ”€â”€ dags/
â”‚ â””â”€â”€ data_ingestion_local.py # Airflow DAG
â”œâ”€â”€ data/ # Local data folder (mounted in containers)
â”œâ”€â”€ logs/ # Airflow logs
â”œâ”€â”€ plugins/ # Custom Airflow plugins (optional)
â”œâ”€â”€ docker-compose.yaml # Airflow multi-container setup
â”œâ”€â”€ .env # Environment variables (ignored in Git)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

---

## ğŸš€ Setup Instructions

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/Adeniceadebo/nyc-taxi-data-pipeline.git
cd nyc-taxi-data-pipeline
